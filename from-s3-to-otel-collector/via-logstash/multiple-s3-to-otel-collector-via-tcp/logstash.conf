input {
  s3 {
    id => "${S3_ID_1}"
    role_arn => "${ROLE_ARN}"
    role_session_name => "session-${S3_ID_1}"
    bucket => "${AWS_BUCKET_1}"
    region => "${AWS_REGION}"
    prefix => "${FOLDER_PREFIX_1}"
    backup_to_dir => "/tmp/${S3_ID_1}"
    interval => 60
    delete => false
    codec => "json"
    sincedb_path => "/usr/share/logstash/pipeline/${S3_ID_1}"
    tags => ["${S3_ID_1}"]
  }
  s3 {
    id => "${S3_ID_2}"
    role_arn => "${ROLE_ARN}"
    role_session_name => "session-${S3_ID_2}"
    bucket => "${AWS_BUCKET_2}"
    region => "${AWS_REGION}"
    prefix => "${FOLDER_PREFIX_2}"
    backup_to_dir => "/tmp/${S3_ID_2}"
    interval => 60
    delete => false
    codec => "json"
    sincedb_path => "/usr/share/logstash/pipeline/${S3_ID_2}"
    tags => ["${S3_ID_2}"]
  }
}

filter {
  if "${S3_ID_1}" in [tags] {
       mutate {
    	add_field => { "from" => "${S3_ID_1}" }
       }
  }
  if "${S3_ID_2}" in [tags] {
     mutate {
       add_field => { "from" => "${S3_ID_2}" }
    }
  }
}

output {
  tcp {
    codec => json_lines # this is required otherwise it will send eveything in a single line
    host => "otel-collector"
    port => 2255
  }
}
